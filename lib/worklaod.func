#!/bin/sh

###############################
###   common function  
###############################
function ca_get_nonmaster_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`grep "Driver container state has changed to RUN" $1 | awk '{print $NF}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_nonmaster_driver_name ()
{
   if [[ -f $1 ]]; then
      driverid=`grep "Got allocation id=" $1 | awk '{ print $7 }'`
      drivername="spark-driver-alloc-"${driverid#*=}".stdout"
      #echo "driver name: $drivername" 
      echo ${drivername}
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_akka_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`grep "driver-" $1 | awk '/State of/ {print $NF}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi 
} 
function ca_get_restapi_driver_status ()
{
   if [[ -f $1 ]]; then 
      driverStatus=`cat $1 | awk '/\"success\"/ {print $3}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_akka_driver_name ()
{
   if [[ -f $1 ]]; then
      drivername=`grep "driver-" $1 | awk '/State of/  {print $7}'`
      #echo "driver name: $drivername" 
      echo $drivername
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_restapi_driver_name ()
{
   if [[ -f $1 ]]; then
     drivername=`sed 's/\"//g' $1 | sed 's/,//g' | awk '/submissionId/  {print $3}'`
     #echo "driver name: $drivername" 
     echo $drivername
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_find_by_key_word ()
{
   if [[ ! -f $1 || -z $2 ]]; then
      echo "error: $0: please specify file name and key word to look up."
      #ca_recover_and_exit 1;
      echo ""
   fi
   findresult=`grep "$2" $1`
   #echo "find by key word: $findresult"
   echo $findresult
}
function ca_assert_num_gt ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -gt "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3" 
  fi
}
function ca_assert_num_ge ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -ge "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_eq ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -eq "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_ne ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -ne "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_lt ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -lt "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_num_le ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -le "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else 
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_str_eq ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" == "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_str_ne ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" != "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_case_filter_equal ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_case_filter  1)val_of_ENV, 2)value_Expected, 3)skip reason."
  elif [[ "$1" != "$2" ]]; then
     echo "case skiped, $3."
     fw_report_save_case_result_in_file $val_case_name "Skip" "$3"
     exit 1;
  else
     echo "case filter was meeted: $1 == $2."
  fi
}
function ca_case_filter_notequal ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_case_filter  1)val_of_ENV, 2)value_notExpected, 3)skip reason."
  elif [[ "$1" == "$2" ]]; then
     echo "case skiped, $3."
     fw_report_save_case_result_in_file $val_case_name "Skip" "$3"
     exit 1;
  else
     echo "case filter was meeted: $1 != $2."
  fi
}
function ca_filter_only_gpfs ()
{
  ca_case_filter_equal "$DIST_FILE_SYSTEM" GPFS "case designed only for GPFS. DIST_FILE_SYSTEM != GPFS" 
}
function ca_filter_only_hdfs ()
{
  ca_case_filter_equal "$DIST_FILE_SYSTEM" HDFS "case designed only for HDFS. DIST_FILE_SYSTEM != HDFS"
}
function ca_filter_only_singleHost ()
{
  ca_case_filter_equal "$HOST_NUM" 1 "case designed only for single host cluser. HOST_NUM != 1"
}
function ca_filter_only_multipleHost ()
{
  ca_case_filter_notequal "$HOST_NUM" 1 "case designed only for multiple host cluser. HOST_NUM == 1"
}
function ca_spark_shell_run_sleep ()
{
if [[ "$#" -ne 3 ]]; then
  echo "usage: ./0 taskNumber taskRunningTime taskType\nvalid value of taskType is 'sync' and 'async'"
  exit 1
fi

taskNum=$1
taskRunTime=$2
taskExpTimeout=`expr ${2} \* 3 / 1000 + 30 `
#echo $taskExpTimeout
if [[ "$3" == "async" ]]; then
   taskType="countAsync"
elif [[ "$3" == "sync" ]]; then
   taskType="count"
else
   echo "error: valid value of taskType is 'sync' and 'async'."
   exit 1
fi


expect<<- END
spawn $SPARK_HOME/bin/spark-shell
set timeout 25
expect "scala>"
send "var numTasks = ${taskNum}\n"
set timeout 3
expect "scala>"
send "var f = sc.parallelize(1 to numTasks, numTasks).map { i => Thread.sleep(${taskRunTime}); i }.${taskType}()\n"
set timeout ${taskExpTimeout}
expect "onStageCompleted: stageId(0)"
exit
END
}
function ca_spark_shell_run_wordcount ()
{
if [[ "$#" -ne 2 ]]; then
  echo "usage: ./0 input output"
  exit 1
fi

inputFile=$1
outputDir=$2
echo $inputFile
echo $outputDir

expect<<- END
spawn $SPARK_HOME/bin/spark-shell
set timeout 100
expect "scala>"
send "val inputFile = sc.textFile(\"${inputFile}\")\r"
set timeout 60
expect "scala>"
send "val counts = inputFile.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_ + _);\r"
set timeout 60
expect "scala>"
send "counts.toDebugString\r"
set timeout 60
expect "scala>"
send "counts.cache()\r"
set timeout 60
expect "scala>"
send "counts.collect().foreach(println)\r"
set timeout 60
expect "scala>"
send "counts.saveAsTextFile(\"${outputDir}\")\r"
set timeout 60
expect "scala>"
send "\n"
exit
END
}
function ca_spark_pyspark_run_sleep ()
{
if [[ "$#" -ne 2 ]]; then
  echo "usage: ./0 taskNumber taskRunningTime"
  exit 1
fi

taskNum=$1
taskRunTime=$2
taskExpTimeout=`expr ${2} \* 3 + 30 `

#>>> import time
#>>> sc.parallelize(xrange(1, 10), 6).map(lambda x: time.sleep(10)).count()


expect<<- END
spawn $SPARK_HOME/bin/pyspark
set timeout 25
expect ">>>"
send "import time\n"
set timeout 3
expect ">>>"
send "sc.parallelize(xrange(1, 10), ${taskNum}).map(lambda x: time.sleep(${taskRunTime})).count()\n"
set timeout ${taskExpTimeout}
expect "onStageCompleted: stageId(0)"
exit
END
}
function ca_assert_file_contain_key_word ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)file 2)keyword 3)fail reason."
  elif [[ ! -f "$1" ]]; then 
     echo "usage: eror, $1 is not a valid file."
  fi
  resultFind=`grep "$2" "$1"`
  if [[ -n $resultFind ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_file_notcontain_key_word ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num 1)file 2)keyword 3)fail reason."
  elif [[ ! -f "$1" ]]; then
     echo "usage: eror, $1 is not a valid file."
  fi
  resultFind=`grep "$2" "$1"`
  if [[ -z $resultFind ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_get_kill_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`cat $1 | awk '/\"success\"/ {print $3}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}

function ca_stop_shuffle_service_by_ego_service ()
{
   currEgosh=`which egosh|grep "egosh$"`
   if [[ -z "$currEgosh" ]]; then
      echo "error: $0: no egosh be found."
      ca_recover_and_exit 1;
   fi
   ca_enable_shuffle_service
   egosh service stop SPARKSS >> /dev/null
}
function ca_start_shuffle_service_by_ego_service ()
{
   currEgosh=`which egosh|grep "egosh$"`
   if [[ -z "$currEgosh" ]]; then
      echo "error: $0: no egosh be found."
      ca_recover_and_exit 1;
   fi
   ca_enable_shuffle_service
   egosh service start SPARKSS >> /dev/null
}
function ca_kill_shuffle_service_process ()
{
    proc_id=`ps -ux |grep Shuffle|grep -v grep`
    if [ -n "$proc_id" ]; then
        ps -ux |grep Shuffle|grep -v grep|awk '{ print $2 }'|xargs kill -9
    fi
}
function ca_start_shuffle_service_by_script ()
{
    if [[ "$#" -ne 1 || -z "$1" ]]; then
     echo "usage: ./ca_start_shuffle_service_by_script  1)tmpout file."
     ca_recover_and_exit 1;
    fi
    ca_enable_shuffle_service
    $SPARK_HOME/bin/spark-class org.apache.spark.deploy.ego.EGOShuffleService &>> $1 &
    sleep 30
    kill %1
}
#function ca_get_shuffle_service_status ()
#{
#    pid=`ps -ux |grep Shuffle|grep -v grep`
#    if [ -n "$pid" ]; then
#        echo "shuffle service has started"
#    else
#        echo "start shuffle failed"
#        ca_recover_and_exit 1;
#    fi
#    sleep 100
#}
function ca_assert_file_exist_in_hdfs ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert 1)Dir path to exist file 2)key word of file name 3)fail reason."
  fi
  outputDir=$1
  filename=$2
  resultFind=`$HADOOP_HOME/bin/hadoop fs -ls $outputDir`
  if [[ $resultFind =~ "$filename" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  #   echo "pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  #  echo "failed"
  fi
}

