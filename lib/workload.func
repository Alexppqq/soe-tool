#!/bin/sh

###############################
###   common function  
###############################
function ca_get_nonmaster_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`grep "Driver container state has changed to RUN" $1 | awk '{print $NF}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_nonmaster_driver_name ()
{
   if [[ -f $1 ]]; then
      driverid=`grep "Got allocation id=" $1 | awk '{ print $7 }'`
      drivername="spark-driver-alloc-"${driverid#*=}".stdout"
      #echo "driver name: $drivername" 
      echo ${drivername}
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_akka_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`grep "driver-" $1 | awk '/State of/ {print $NF}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi 
} 
function ca_get_restapi_driver_status ()
{
   if [[ -f $1 ]]; then 
      driverStatus=`cat $1 | awk '/\"success\"/ {print $3}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_akka_driver_name ()
{
   if [[ -f $1 ]]; then
      drivername=`grep "driver-" $1 | awk '/State of/  {print $7}'`
      #echo "driver name: $drivername" 
      echo $drivername
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_get_restapi_driver_name ()
{
   if [[ -f $1 ]]; then
     drivername=`sed 's/\"//g' $1 | sed 's/,//g' | awk '/submissionId/  {print $3}'`
     #echo "driver name: $drivername" 
     echo $drivername
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_find_by_key_word ()
{
   if [[ ! -f $1 || -z $2 ]]; then
      echo "error: $0: please specify file name and key word to look up."
      #ca_recover_and_exit 1;
      echo ""
   fi
   findresult=`grep "$2" $1`
   #echo "find by key word: $findresult"
   echo $findresult
}
function ca_assert_num_gt ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_gt 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -gt "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3" 
  fi
}
function ca_assert_num_ge ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_ge 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -ge "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_eq ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_eq 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -eq "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_ne ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_ne 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -ne "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass" 
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_num_lt ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_lt 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -lt "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_num_le ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_num_le 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" -le "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else 
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"    
  fi
}
function ca_assert_str_eq ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_str_eq 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" == "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_str_ne ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_str_ne 1)variable, 2)threshold, 3)fail reason."
  elif [[ "$1" != "$2" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_case_filter_equal ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_case_filter_equal  1)val_of_ENV, 2)value_Expected, 3)skip reason."
  elif [[ "$1" != "$2" ]]; then
     echo "case skiped, $3."
     fw_report_save_case_result_in_file $val_case_name "Skip" "$3"
     exit 1;
  else
     echo "case filter was meeted: $1 == $2."
  fi
}
function ca_case_filter_notequal ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_case_filter_notequal  1)val_of_ENV, 2)value_notExpected, 3)skip reason."
  elif [[ "$1" == "$2" ]]; then
     echo "case skiped, $3."
     fw_report_save_case_result_in_file $val_case_name "Skip" "$3"
     exit 1;
  else
     echo "case filter was meeted: $1 != $2."
  fi
}
function ca_filter_only_gpfs ()
{
  ca_case_filter_equal "$DIST_FILE_SYSTEM" GPFS "case designed only for GPFS. DIST_FILE_SYSTEM != GPFS" 
}
function ca_filter_only_hdfs ()
{
  ca_case_filter_equal "$DIST_FILE_SYSTEM" HDFS "case designed only for HDFS. DIST_FILE_SYSTEM != HDFS"
}
function ca_filter_only_singleHost ()
{
  ca_case_filter_equal "$HOST_NUM" 1 "case designed only for single host cluser. HOST_NUM != 1"
}
function ca_filter_only_multipleHost ()
{
  ca_case_filter_notequal "$HOST_NUM" 1 "case designed only for multiple host cluser. HOST_NUM == 1"
}
function ca_spark_shell_run_sleep ()
{
  if [[ "$#" -ne 3 ]]; then
    echo -e "usage: $0 taskNumber taskRunningTime taskType <end_condition>\n  \
                    the valid value of taskType is 'sync' and 'async'"
    return 1
  fi

  local taskNum=$1
  local taskRunTime=$2
  if [[ "$3" == "async" ]]; then
     taskType="countAsync"
  elif [[ "$3" == "sync" ]]; then
     taskType="count"
  else
     echo "error: valid value of taskType is 'sync' and 'async'."
     return 1
  fi
  local end_condition=${4:-"onStageCompleted: stageId(0)"}

  expect<<- END
  spawn $SPARK_HOME/bin/spark-shell
  set timeout -1
  expect "scala>"
  send "var numTasks = ${taskNum}\n"
  expect "scala>"
  send "var f = sc.parallelize(1 to numTasks, numTasks).map { i => Thread.sleep(${taskRunTime}); i }.${taskType}()\n"
  expect "${end_condition}"
  exit
END
}
function ca_spark_shell_run_wordcount ()
{
if [[ "$#" -ne 2 ]]; then
  echo "usage: ./0 input output"
  exit 1
fi

inputFile=$1
outputDir=$2
echo $inputFile
echo $outputDir

expect<<- END
spawn $SPARK_HOME/bin/spark-shell
set timeout 100
expect "scala>"
send "val inputFile = sc.textFile(\"${inputFile}\")\r"
set timeout 60
expect "scala>"
send "val counts = inputFile.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_ + _);\r"
set timeout 60
expect "scala>"
send "counts.toDebugString\r"
set timeout 60
expect "scala>"
send "counts.cache()\r"
set timeout 60
expect "scala>"
send "counts.collect().foreach(println)\r"
set timeout 60
expect "scala>"
send "counts.saveAsTextFile(\"${outputDir}\")\r"
set timeout 60
expect "scala>"
send "\n"
exit
END
}
function ca_spark_pyspark_run_sleep ()
{
if [[ "$#" -ne 2 ]]; then
  echo "usage: ./0 taskNumber taskRunningTime"
  exit 1
fi

taskNum=$1
taskRunTime=$2
taskExpTimeout=`expr ${2} \* 3 + 30 `

#>>> import time
#>>> sc.parallelize(xrange(1, 10), 6).map(lambda x: time.sleep(10)).count()


expect<<- END
spawn $SPARK_HOME/bin/pyspark
set timeout 25
expect ">>>"
send "import time\n"
set timeout 3
expect ">>>"
send "sc.parallelize(xrange(1, 10), ${taskNum}).map(lambda x: time.sleep(${taskRunTime})).count()\n"
set timeout ${taskExpTimeout}
expect "onStageCompleted: stageId(0)"
exit
END
}
function ca_assert_file_contain_key_word ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_file_contain_key_word 1)file 2)keyword 3)fail reason."
  elif [[ ! -f "$1" ]]; then 
     echo "usage: eror, $1 is not a valid file."
  fi
  resultFind=`grep "$2" "$1"`
  if [[ -n $resultFind ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_assert_file_notcontain_key_word ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert_file_notcontain_key_word 1)file 2)keyword 3)fail reason."
  elif [[ ! -f "$1" ]]; then
     echo "usage: eror, $1 is not a valid file."
  fi
  resultFind=`grep "$2" "$1"`
  if [[ -z $resultFind ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  fi
}
function ca_get_kill_driver_status ()
{
   if [[ -f $1 ]]; then
      driverStatus=`cat $1 | awk '/\"success\"/ {print $3}'`
      #echo "driver success to submit: $driverStatus"
      echo $driverStatus
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}

function ca_stop_shuffle_service_by_ego_service ()
{
   currEgosh=`which egosh|grep "egosh$"`
   if [[ -z "$currEgosh" ]]; then
      echo "error: $0: no egosh be found."
      ca_recover_and_exit 1;
   fi
   ca_enable_shuffle_service
   egosh service stop SPARKSS >> /dev/null
}
function ca_start_shuffle_service_by_ego_service ()
{
   currEgosh=`which egosh|grep "egosh$"`
   if [[ -z "$currEgosh" ]]; then
      echo "error: $0: no egosh be found."
      ca_recover_and_exit 1;
   fi
   ca_enable_shuffle_service
   egosh service start SPARKSS >> /dev/null
}
function ca_kill_shuffle_service_process ()
{
    proc_id=`ps -ux |grep Shuffle|grep -v grep`
    if [ -n "$proc_id" ]; then
        ps -ux |grep Shuffle|grep -v grep|awk '{ print $2 }'|xargs kill -9
    fi
}
function ca_start_shuffle_service_by_script ()
{
    if [[ "$#" -ne 1 || -z "$1" ]]; then
     echo "usage: ./ca_start_shuffle_service_by_script  1)tmpout file."
     ca_recover_and_exit 1;
    fi
    ca_enable_shuffle_service
    $SPARK_HOME/bin/spark-class org.apache.spark.deploy.ego.EGOShuffleService &>> $1 &
    sleep 30
    kill %1
}
#function ca_get_shuffle_service_status ()
#{
#    pid=`ps -ux |grep Shuffle|grep -v grep`
#    if [ -n "$pid" ]; then
#        echo "shuffle service has started"
#    else
#        echo "start shuffle failed"
#        ca_recover_and_exit 1;
#    fi
#    sleep 100
#}
function ca_assert_file_exist_in_hdfs ()
{
  if [[ "$#" -ne 3 || -z "$1" || -z "$2" || -z "$3" ]]; then
     echo "usage: ./ca_assert 1)Dir path to exist file 2)key word of file name 3)fail reason."
  fi
  outputDir=$1
  filename=$2
  resultFind=`$HADOOP_HOME/bin/hadoop fs -ls $outputDir`
  if [[ $resultFind =~ "$filename" ]]; then
     fw_report_save_case_result_in_file $val_case_name "Pass"
  #   echo "pass"
  else
     fw_report_save_case_result_in_file $val_case_name "Fail" "$3"
  #  echo "failed"
  fi
}

function ca_find_keyword_timeout ()
{
  if [ $# -le 2 ]; then
    echo "usage: $0 <file> <keyword> <timeout>"
    return -1
  fi

  local filename=${1:-''}
  local keyword=${2:-''}
  local timeout=${3:-1}

  if [ ! -f $filename ]; then
    echo "the file $filename does not exist"
    return 1
  fi

  if [ -z "$keyword" ]; then
    echo "the keyword $keyword should not blank"
    return 1
  fi

  if [ $timeout -le 0 ]; then
    echo "the timeout $timeout should be greate and equal to 1"
    return 1
  fi

  while [ $timeout -ne 0 ];do
    grep "${keyword}" ${filename}
    [ $? -eq 0 ] && break
    sleep 1
    timeout=$(( $timeout - 1 ))
  done
}

function ca_kill_process ()
{
  if [[ "$#" -ne 1 || -z "$1" ]]; then
     echo "usage: ./ca_kill_process 1)Key for process to be killed."
  fi
  proc_id=`ps -ux |grep "$1"|grep -v grep`
    if [ -n "$proc_id" ]; then
        ps -ux |grep "$1"|grep -v grep|awk '{ print $2 }'|xargs kill
        echo "$1 has been killed"
    else
        echo "$1 has not existed"
        ca_recover_and_exit 1;
    fi
}
function ca_get_nonmaster_driver_stderr ()
{
   if [[ -f $1 ]]; then
      driverid=`grep "Got allocation id=" $1 | awk '{ print $7 }'`
      drivername="spark-driver-alloc-"${driverid#*=}".stderr"
      #echo "driver name: $drivername"
      echo ${drivername}
   else
      echo "error: $0: please specify a file."
      #ca_recover_and_exit 1;
      echo ""
   fi
}
function ca_keep_check_in_file
{
if [[ "$#" -ne 4 || -z "$1" || ! -f "$2" || -z "$3" || -z "$4" ]]; then
     echo "usage: ./ca_keep_check_in_file  1)key, 2)file, 3)inteval_sec, 4)timeout_sec."
     ca_recover_and_exit 1
fi
resultFind=`grep "$1" "$2"`
SECONDS=0
while [[ "$SECONDS" -le "$4" && -z "$resultFind" ]]; do
    echo "$SECONDS"
    sleep $3
    resultFind=`grep "$1" "$2"`
done

if [ -n "$resultFind" ]; then
    echo "$1 has found in $2"
else
    echo "Timeout! Can't find $1 in $2 in $4 secs "
    ca_recover_and_exit
fi
}
function ca_check_cleanup ()
{
if [[ ! -d $1 || ! -x $1 ]]; then
  echo "fail;usage: ./ca_check_cleanup 1)sparklocaldir"
  return 1;
else
  tmp_local_dir=$1
fi

for tmpfile in `ls $tmp_local_dir`; do
  case $tmpfile in
    driver-*|blockmgr-*|spark-* )
       echo "fail;$tmp_local_dir/$tmpfile"
       return 1;;
    app-* )
       for tmpappfile in `ls $tmp_local_dir/$tmpfile/`; do
           case $tmpappfile in
              *_lock|*_cache  )
                #echo "success;none";;
                ;;
              * )
                echo "fail;$tmp_local_dir/$tmpfile/$tmpappfile"
                return 1;;
           esac
      done;;
   * )
       echo "fail;$tmp_local_dir/$tmpfile"
       return 1;;
  esac
done
#no invalid file
echo "success;none"
return 0;
}

function ca_get_driver_id ()
{
  if [ $# -ne 1 ]; then
    echo "usage: $0 <output>"
    return 1
  fi

  local file=${1:-''}
  local keyword="ClientEndpoint: Driver successfully submitted"
  if [ ! -f $file ]; then
    echo "the file $file does not exists"
    return 1
  fi

  echo $(ca_find_keyword_timeout $file $keyword 30  |  awk '{print $NF}')
}

function ca_kill_spark_app ()
{
  if [ $# -ne 2 ]; then
    echo "usage: $0 <driver id> <master:port>"
    return 1
  fi

  local driver_id=${1:-''}
  local master=${2:-'${SYM_MASTER_HOST}:6066'} # port should be rest port, default is 6066

  if [ -z $driver_id ]; then
    echo "the driver id is blank"
    return 1
  fi

  $SPARK_HOME/bin/spark-submit --kill $driver_id --master $master
  [ $? -eq 0 ] || echo ""
}

